---
title: "Análisis Multivariado - Práctica 2, Pt. 2, Ej. 9"
author: "Gonzalo Barrera Borla"
date: "18/10/2019"
output:
  pdf_document: default
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(tinytex.verbose = TRUE)
```

# Librerias
```{r}
library(mvtnorm) # Distribuciones multivariadas
library(tidyverse) # manipulación de datos en general, graficos
```

# 2-2-9: Test de Hotelling para muestras T-multivariadas 

Se quiere ahora testear $H_{0} : \mu=\mu_{0}$ con $\mu_{0}=\mathbf{0}$ cuando $\mathbf{x}_{i} \sim \mathcal{T}_{p, k}(\mu, \Sigma)$ usando el
estadístico
$$
T=n\left(\overline{\mathbf{x}}-\mu_{0}\right)^{\mathrm{T}} \mathbf{S}^{-1}\left(\overline{\mathbf{x}}-\mu_{0}\right)
$$

a. Hacer una simulación para decidir qué resultado obtendría si se usara el percentil de T como si las observaciones fueran normales. Use $k = 1, 2, 4, 10$, $p = 2, 4$ y $n = 20$.
b. Armar un mecanismo bootstrap para testear $H_0$ en este caso.

## A: Simulación

Sabemos que cuando $\mathbf{x}_{i} \sim \mathcal{N}_{p}(\mu, \Sigma) \Rightarrow \: \tfrac{n-p}{p(n-1)} T^2\sim \mathcal{F}_{p, n-p}\left(\lambda^{2}\right)$, y por ende podemos calcular el p-valor correspondiente al $T^2_{obs}, \: p_i$ en cada simulación. 
Como el estadístico de Hotelling es invariante bajo transformaciones no-singulares de las $\mathbf{x}_{i}$, consideramos sin pérdida de generalidad $\Sigma = \mathbf{I}_p$.

Además de simular los valores del estadístico $T^2$ cuando la muestra es $\mathcal{T}_{p, k}$ para cada tupla $(n, p, k)$ propuesta, consideramos como caso testigo la normal multivariada $\mathcal{N}_p(0,\mathbf{I}_p)$. Como la normal multivariada no tiene grados de libertad como parámetro, nos referimos a ésta con $k = \text{NA}$.

Comenzamos seteamos los parámetros de la simulación
```{r}
nsims <- 10000
rango_k <- c(1, 2, 4, 10, NA)
rango_p <- c(2, 4)
rango_n <- c(20)
```

Genero un data frame vacio para guardar los resultados de la simulacion. Suele ser más eficiente "reservar" el espacio en disco con un data frame  de las dimensiones necesarias y `NA` en todas las posiciones, e ir llenándolo, que usar `rbind(df, nuevaFila)` para ir anexando filas reiteradamente a un data frame.
```{r}
vars_df <- c("p", "n", "k", "nsim", "T0sq", "F0", "p.value")
resultados <- data.frame(matrix(
  ncol = length(vars_df),
  nrow = nsims * (length(rango_k) * length(rango_p) * length(rango_n))
))
colnames(resultados) <- vars_df
```

Y ahora generamos `nsims` muestras para cada tupla de parámetros, y guardamos los estadísticos de interés en el data frame. Usamos un índice `i` para ir avanzando la posición en el mismo.

\newpage

```{r, cache = T}
i <- 1 # Índice de fila para los resultados
for (p in rango_p) {
  for (n in rango_n) {
    for (nsim in seq.int(nsims)) {
      for (k in rango_k) {
        set.seed(nsim) # Repito la semilla en cada "ronda" de simulación 
        if (is.na(k)) { # muestra Normal de referencia
          X <- rmvnorm(n, sigma = diag(p))
        } else {
          X <- rmvt(n, sigma = diag(p), df = k)
        }
        y <- colMeans(X)
        W <- cov(X)
        T0sq <- n * as.numeric(t(y) %*% solve(W) %*% y) 
        F0 <- T0sq * (n-p) / ((n-1) * p)
        p.value <- 1 - pf(F0, p, n - p)        
        
        vals <- c(p, n, k, nsim, T0sq, F0, p.value)
        resultados[i,] <- vals
        i <- i+1
      }
    }
  }
}
```

La tabla resultante contiene los resultados de un simulación por fila. En particular, nos interesa estudiar la distribución de los p-valores.

```{r, echo = F}
resultados <- as_tibble(resultados) %>%
  mutate(k = fct_explicit_na(as_factor(k), na_level = "Normal"))

arrange(resultados, nsim, p, k) %>% 
  head(12) %>%
  knitr::kable(digits = 3)
```

Si la distribución del estadísto $T^2_0$ (`T0sq`) fuese efectivamente Hotelling, los p-valores del test deberían tener una distribución uniforme entre 0 y 1. Recordemos que $k=\text{NA}$ se utilizó para guardar los resultados de la simulación normal de referencia, en cuyo caso _no se utiliza el parámetro k_.

```{r, echo = F}
resultados %>%
  ggplot(aes(p.value, color = k)) +
  geom_density() +
  facet_wrap(~p, labeller = label_both) +
  theme(legend.position = "bottom") +
  labs(title = "Densidad empírica del p-valor de test, según p y k",
       color = "G. Libertad", x = "P-valor", y = "Densidad empírica")
```

Para $k=1,\:k=2$, cuando la varianza de la T multivariada no es finita, la densidad no está uniformemente repartida entre los p-valores. Para $k$ más grande, o cuando la distribución es normal multivariada, la densidad empírica sí pareciera asemejarse a una densidad uniforme en (0, 1).

Para hacer una comparación más directa, podemos elegir un nivel de significación $\alpha=0.05$, y ver cómo se comparan los niveles de significación empíricos $\hat{\alpha}$ (id est, la cantidad de simulaciones con un p-valor del test menor a $\alpha$).

```{r, echo = F}
alfa <- 0.05
resultados %>%
  group_by(k, n, p) %>%
  summarise(alfa_emp = mean(p.value < alfa)) %>%
  ggplot(aes(k, alfa_emp, color = factor(p), group = p)) +
  geom_point() + geom_line(linetype = "dashed") +
  geom_hline(yintercept = alfa, color = "gray") +
  theme(legend.position = "bottom") +
  labs(title = expression(
    paste(hat(alpha), " para T con distintos GL y Normal multivariadas (", alpha, "=0.05)")),
    x = "G. Libertad", y = expression(hat(alpha)), color = "p")
```

Por la distribución poco uniforme de los p-valores para valores bajos de $k$, el test basado en el estadístico de Hotelling rechaza muy por debajo de la proporción nominal $\alpha$. Esto es razonable: cuando $k \leq 2 \Rightarrow \text{Var}(\mathbf{x}) = +\infty$, y los intervalos de confianza alrededor de la media muestral serán tan amplios que prácticamente siempre incluirán al cero. A medida que $k$ crece, $\mathcal{T}_{p, k} \stackrel{D}{\rightarrow} \mathcal{N}_p$ y la significación empírica se asemeja a la nominal. Aún así, existe cierta variabilidad alrededor del verdadero valor $\alpha=0.05$.

## B: Bootstrap Paramétrico

El proceso de bootstrap será el siguiente:

1. Fijamos la semilla, y generamos una muestra de tamaño $n$ de VA $\mathbf{x}_i \sim \mathcal{T}_{p,k}(\mu=0,\Sigma=\mathbf{I}_p)$.
2. Suponiendo que queremos testear $H_0: \mu = \mu_0$ con $\Sigma$ desconocida utilizaremos el estimador insesgado de $\Sigma$, $\mathbf{S}$, y generaremos $n_{boot}$ muestras de tamaño $n$ de una $\mathcal{T}_{p,k}(\mu=\mu_0,\Sigma=\mathbf{S})$.
3. Computamos el estadístico $T_0^2$ para la muestra original y los $n_{boot}$ estadísticos $T^2_{boot,i}$ sobre las muestras sintéticas, y el p-valor asociado al test sobre la muestra original, será
$$
\text{p-valor}_{boot} = \frac{\#\{i:\:T^2_{boot,i} > T^2_0\}}{n_{boot}+1}
$$

\newpage

```{r}
bootstrap.test <- function(n, p, k, mu0 = rep(0, p), nboot=1000) {
  # X0: matriz muestral (n*p), de VAIID T multivariadas (0, I_p) con k GL
  X0 <- rmvt(n, sigma = diag(p), df = k)
  x_0 <- colMeans(X0)
  S0 <- cov(X0)
  T0 <- as.numeric(n * t(x_0 - mu0) %*% solve(S0) %*% (x_0 - mu0))
  Tboot <- vector("numeric", nboot)
  for (i in seq.int(nboot)) {
    # Bajo H0, las observaciones tienen media mu0 y varianza estimada S
    X <- rmvt(n, delta = mu0, sigma = diag(p))
    x_ <- colMeans(X)
    S <- cov(X)
    Tboot[i] <- as.numeric(n * t(x_ - mu0) %*% solve(S) %*% (x_ - mu0)) 
  }
  p.value <- sum(Tboot > T0)/(nboot+1)
  return(p.value)
}
```

Si el proceso se comporta como uno espera, deberíamos obtener p-valores cercanos a 1 cuando $\mu_0=0$, y tender a cero a medida que $\|\mu_0\|$ crece. Fijamos $n=20,p=2,k=3$ y consideramos la serie de $\mu_{0,i}=c_i \times1_p, c_i=\{0, 0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 1\}$:

```{r, cache = T}
rango_c <- c(0, 0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 1)
pval <- vector("numeric", length(rango_c))
for (i in seq_along(rango_c)) {
  set.seed(42)
  pval[i] <- bootstrap.test(n = 20, p = 2, k = 3, mu0 = rep(rango_c[i], 2)) }
```


```{r, echo = F, fig.height=4}
tibble(c = rango_c, pv = pval) %>%
  ggplot(aes(c, pv)) +
  geom_point() +
  geom_line(linetype = "dashed") +
  labs(title = "P-valores para el procedimiento bootstrap y distintas hipótesis nulas",
       x = expression(paste("'c' en ", H[0] : mu, " = ", mu[0], " = (c, ..., c)'")),
       y = expression(pval[boot]))
```

El test se comporta como uno esperaría, con una probabilidad de rechazo que aumenta (p-valor que disminuye) a medida que nos alejamos de la verdadera distribución $\mu=0$.